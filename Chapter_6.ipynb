{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Chapter 6",
      "provenance": [],
      "authorship_tag": "ABX9TyOLkjPBbSmjukrevztWEfRC",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ramalouse/hands-on-ML/blob/master/Chapter_6.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cc2BZmF53Rzn"
      },
      "source": [
        "import sys\n",
        "assert sys.version_info >= (3, 5)\n",
        "\n",
        "# Scikit-Learn ≥0.20 is required\n",
        "import sklearn\n",
        "assert sklearn.__version__ >= \"0.20\"\n",
        "\n",
        "# Common imports\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "# to make this notebook's output stable across runs\n",
        "np.random.seed(42)\n",
        "\n",
        "# To plot pretty figures\n",
        "%matplotlib inline\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "mpl.rc('axes', labelsize=14)\n",
        "mpl.rc('xtick', labelsize=12)\n",
        "mpl.rc('ytick', labelsize=12)\n",
        "\n",
        "# Where to save the figures\n",
        "PROJECT_ROOT_DIR = \".\"\n",
        "CHAPTER_ID = \"decision_trees\"\n",
        "IMAGES_PATH = os.path.join(PROJECT_ROOT_DIR, \"images\", CHAPTER_ID)\n",
        "os.makedirs(IMAGES_PATH, exist_ok=True)\n",
        "\n",
        "def save_fig(fig_id, tight_layout=True, fig_extension=\"png\", resolution=300):\n",
        "    path = os.path.join(IMAGES_PATH, fig_id + \".\" + fig_extension)\n",
        "    print(\"Saving figure\", fig_id)\n",
        "    if tight_layout:\n",
        "        plt.tight_layout()\n",
        "    plt.savefig(path, format=fig_extension, dpi=resolution)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oDss10Nk2QS2",
        "outputId": "bdf12456-301e-4b3e-d2b3-1f1b93f38cab",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from sklearn.datasets import load_iris\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "iris = load_iris()\n",
        "X = iris.data[:, 2:] # petal length and width\n",
        "y = iris.target\n",
        "\n",
        "tree_clf = DecisionTreeClassifier(max_depth=2)\n",
        "tree_clf.fit(X, y)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
              "                       max_depth=2, max_features=None, max_leaf_nodes=None,\n",
              "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
              "                       min_samples_leaf=1, min_samples_split=2,\n",
              "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
              "                       random_state=None, splitter='best')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_BYUDxh628xM"
      },
      "source": [
        "from sklearn.tree import export_graphviz\n",
        "\n",
        "export_graphviz(\n",
        "    tree_clf,\n",
        "    out_file=os.path.join(IMAGES_PATH, \"iris_tree.dot\"),\n",
        "    feature_names=iris.feature_names[2:],\n",
        "    class_names=iris.target_names,\n",
        "    rounded=True,\n",
        "    filled=True\n",
        "    )"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iqsegmVB3lF1",
        "outputId": "2511961a-907a-4cc0-e13d-fca6a03aa2bd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "tree_clf.predict_proba([[5, 1.5]])"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.        , 0.90740741, 0.09259259]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6JFyzDmI4ipA",
        "outputId": "103f701a-7be0-4fcc-9bf0-c42d5ddb0262",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "tree_clf.predict([[5, 1.5]])"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0uUKFCCs4k_m",
        "outputId": "26e6a605-8d3b-4ef1-964b-5e6aa6c51c63",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from sklearn.tree import DecisionTreeRegressor\n",
        "\n",
        "tree_reg = DecisionTreeRegressor(max_depth=2)\n",
        "tree_reg.fit(X, y)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DecisionTreeRegressor(ccp_alpha=0.0, criterion='mse', max_depth=2,\n",
              "                      max_features=None, max_leaf_nodes=None,\n",
              "                      min_impurity_decrease=0.0, min_impurity_split=None,\n",
              "                      min_samples_leaf=1, min_samples_split=2,\n",
              "                      min_weight_fraction_leaf=0.0, presort='deprecated',\n",
              "                      random_state=None, splitter='best')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cGEPjOZ64pPI"
      },
      "source": [
        ""
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "duc9y0NE4xhE"
      },
      "source": [
        "# Exercises"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f7L7Tbd25iBD"
      },
      "source": [
        "# 1. What is the approximate depth of a Decision Tree trained (without restrictions) on a training set with one million instances?\n",
        "\n",
        "Tree depth is found with log_2_(m) where m is number of leaves.\n",
        "\n",
        "In this case **log_2_(10^6) equates to roughly 20**.\n",
        "This means the depth of a decision tree with one million instances would be at least 20"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eDDHOU_t5qY0"
      },
      "source": [
        "# 2. Is a node’s Gini impurity generally lower or greater than its parent’s? Is it generally lower/greater, or always lower/greater?\n",
        "\n",
        "A node's gini impurity is usually lower than its parent. It can be higher, but only by the means that the other child node has a lower impurity, which reduces the weighted sum of the child nodes below that of the parent node."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R8y0O38_5vIC"
      },
      "source": [
        "# 3. If a Decision Tree is overfitting the training set, is it a good idea to try decreasing max_depth?\n",
        "\n",
        "Reducing the max_depth of a decision tree should help it to better fit the training set, as this well help to regularize the model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VYEi2oDg5zOw"
      },
      "source": [
        "# 4. If a Decision Tree is underfitting the training set, is it a good idea to try scaling the input features?\n",
        "\n",
        "Decisison trees ignore the scaling of input features, as this is not the important factor. So no, it is not a good ideas to scale the input features of a decision tree underfits the training set."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "__0BPBRp52of"
      },
      "source": [
        "# 5. If it takes one hour to train a Decision Tree on a training set containing 1 million instances, roughly how much time will it take to train another Decision Tree on a training set containing 10 million instances?\n",
        "\n",
        "Decision tree training complexity is O(n × m log(m)). Multiplying the training set will multiply the training time by K = (n × 10m × log(10m)) / (n × m × log(m)) = 10 × log(10m) / log(m)\n",
        "\n",
        "If m=10^6, K = 11.7 (roughly). \n",
        "\n",
        "So the training time would be **11.7 hours**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nG2M1hRY59Jx"
      },
      "source": [
        "# 6. If your training set contains 100,000 instances, will setting presort=True speed up training?\n",
        "\n",
        "Presorting a training set only speeds up training if the dataset is no larger than a few thousand instances. \n",
        "\n",
        "Given that the training set contains 100,000 instances, **training will take much longer with presort=True** "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AsgQ3y3T6Anj"
      },
      "source": [
        "# 7. Train and fine-tune a Decision Tree for the moons dataset by following these steps:\n",
        "#a. Use make_moons(n_samples=10000, noise=0.4) to generate a moons dataset.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OLuEeznpW6HG"
      },
      "source": [
        "from sklearn.datasets import make_moons\n",
        "\n",
        "X, y = make_moons(n_samples=10000, noise=0.4, random_state=42)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Av4g8C4jW6n6"
      },
      "source": [
        "#b. Use train_test_split() to split the dataset into a training set and a test set.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2idYwHwpW89s"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gb_luHh3W9ty"
      },
      "source": [
        "#c. Use grid search with cross-validation (with the help of the GridSearchCV class) to find good hyperparameter values for a DecisionTreeClassifier. (Hint: try various values for max_leaf_nodes)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iCFDN5bfXAp3",
        "outputId": "622dabff-7dde-4d6f-c0a7-2e1fcb175e22",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "params = {'max_leaf_nodes': list(range(2, 100)), 'min_samples_split': [2, 3, 4]}\n",
        "grid_search_cv = GridSearchCV(DecisionTreeClassifier(random_state=42), params, verbose=1, cv=3)\n",
        "\n",
        "grid_search_cv.fit(X_train, y_train)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 3 folds for each of 294 candidates, totalling 882 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 882 out of 882 | elapsed:    9.3s finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(cv=3, error_score=nan,\n",
              "             estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None,\n",
              "                                              criterion='gini', max_depth=None,\n",
              "                                              max_features=None,\n",
              "                                              max_leaf_nodes=None,\n",
              "                                              min_impurity_decrease=0.0,\n",
              "                                              min_impurity_split=None,\n",
              "                                              min_samples_leaf=1,\n",
              "                                              min_samples_split=2,\n",
              "                                              min_weight_fraction_leaf=0.0,\n",
              "                                              presort='deprecated',\n",
              "                                              random_state=42,\n",
              "                                              splitter='best'),\n",
              "             iid='deprecated', n_jobs=None,\n",
              "             param_grid={'max_leaf_nodes': [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12,\n",
              "                                            13, 14, 15, 16, 17, 18, 19, 20, 21,\n",
              "                                            22, 23, 24, 25, 26, 27, 28, 29, 30,\n",
              "                                            31, ...],\n",
              "                         'min_samples_split': [2, 3, 4]},\n",
              "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
              "             scoring=None, verbose=1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OTe9TFIAXs3h",
        "outputId": "8b5ca34b-badb-4ec1-db11-fa9284ebc20e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "grid_search_cv.best_estimator_"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
              "                       max_depth=None, max_features=None, max_leaf_nodes=17,\n",
              "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
              "                       min_samples_leaf=1, min_samples_split=2,\n",
              "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
              "                       random_state=42, splitter='best')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Za1LycwAXDji"
      },
      "source": [
        "#d. Train it on the full training set using these hyperparameters, and measure your model’s performance on the test set. You should get roughly 85% to 87% accuracy."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tJVZyXZsXGK2",
        "outputId": "0d6ea343-bf7e-4b98-963f-099329c31c93",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "y_pred = grid_search_cv.predict(X_test)\n",
        "accuracy_score(y_test, y_pred)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8695"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LRtjJsIG6RXT"
      },
      "source": [
        "# 8. Grow a forest by following these steps:\n",
        "#a. Continuing the previous exercise, generate 1,000 subsets of the training set, each containing 100 instances selected randomly. Hint: you can use Scikit-Learn’s ShuffleSplit class for this.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QiK4cL71XIuF"
      },
      "source": [
        "from sklearn.model_selection import ShuffleSplit\n",
        "\n",
        "n_trees = 1000\n",
        "n_instances = 100\n",
        "\n",
        "mini_sets = []\n",
        "\n",
        "rs = ShuffleSplit(n_splits=n_trees, test_size=len(X_train) - n_instances, random_state=42)\n",
        "for mini_train_index, mini_test_index in rs.split(X_train):\n",
        "    X_mini_train = X_train[mini_train_index]\n",
        "    y_mini_train = y_train[mini_train_index]\n",
        "    mini_sets.append((X_mini_train, y_mini_train))"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h7KBzqmA6jAH"
      },
      "source": [
        "#b. Train one Decision Tree on each subset, using the best hyperparameter values found in the previous exercise. Evaluate these 1,000 Decision Trees on the test set. Since they were trained on smaller sets, these Decision Trees will likely perform worse than the first Decision Tree, achieving only about 80% accuracy.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ySQat8k3XLFZ",
        "outputId": "d8a6876e-96d7-4163-cfaf-ad533ee1fe4f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from sklearn.base import clone\n",
        "\n",
        "forest = [clone(grid_search_cv.best_estimator_) for _ in range(n_trees)]\n",
        "\n",
        "accuracy_scores = []\n",
        "\n",
        "for tree, (X_mini_train, y_mini_train) in zip(forest, mini_sets):\n",
        "    tree.fit(X_mini_train, y_mini_train)\n",
        "    \n",
        "    y_pred = tree.predict(X_test)\n",
        "    accuracy_scores.append(accuracy_score(y_test, y_pred))\n",
        "\n",
        "np.mean(accuracy_scores)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8054499999999999"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gyai6Q4UXLQ2"
      },
      "source": [
        "#c. Now comes the magic. For each test set instance, generate the predictions of the 1,000 Decision Trees, and keep only the most frequent prediction (you can use SciPy’s mode() function for this). This approach gives you majority-vote predictions over the test set.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YhLo4MWAXM-1"
      },
      "source": [
        "Y_pred = np.empty([n_trees, len(X_test)], dtype=np.uint8)\n",
        "\n",
        "for tree_index, tree in enumerate(forest):\n",
        "    Y_pred[tree_index] = tree.predict(X_test)\n",
        "\n",
        "from scipy.stats import mode\n",
        "\n",
        "y_pred_majority_votes, n_votes = mode(Y_pred, axis=0)"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iPD7MsJqXNHd"
      },
      "source": [
        "#d. Evaluate these predictions on the test set: you should obtain a slightly higher accuracy than your first model (about 0.5 to 1.5% higher). Congratulations, you have trained a Random Forest classifier! "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KbLiJuIZXOP1",
        "outputId": "4adf83b0-9134-49d2-dc58-633d374f5254",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "accuracy_score(y_test, y_pred_majority_votes.reshape([-1]))\n"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.872"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    }
  ]
}